{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pytorch_lightning as pl\n",
    "import flash \n",
    "from flash.image import ImageClassifier\n",
    "from flash.core.data.data_module import DataModule\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "arr = np.random.randn(10, 5, 3)\n",
    "arr = arr.transpose(2, 0, 1)\n",
    "arr.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 10, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Loading the data (signs)\n",
    "def get_imgs_labels(h5_file_path):\n",
    "    f = h5py.File(h5_file_path, \"r\")\n",
    "    ds_keys = [key for key in f.keys()]\n",
    "    imgs = np.array(f[ds_keys[1]])    \n",
    "    labels = np.array(f[ds_keys[2]])\n",
    "    list_classes = np.array(f[ds_keys[0]])\n",
    "    imgs = np.transpose(imgs, (0, 3, 1, 2))\n",
    "    return imgs, labels, list_classes\n",
    "\n",
    "train_x, train_y, train_classes = get_imgs_labels(\"./datasets/train_signs.h5\")\n",
    "test_x, test_y, test_classes = get_imgs_labels(\"./datasets/test_signs.h5\")\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1080, 3, 64, 64) (1080,)\n",
      "(120, 3, 64, 64) (120,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# CONSTANTS\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#img = Image.fromarray(np.uint8(test_x[0])).convert('RGB')\n",
    "#img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from flash.core.data.data_source import DataSource, DefaultDataKeys\n",
    "from torchvision.datasets.folder import make_dataset\n",
    "from typing import Any, Dict, Iterable , Mapping, Sequence, Callable   \n",
    "\n",
    "class SignsDataSource(DataSource):    \n",
    "    def load_data(self, h5_file_path: str) -> Sequence[Mapping[str, Any]]:\n",
    "        f = h5py.File(h5_file_path, \"r\")\n",
    "        ds_keys = [key for key in f.keys()]\n",
    "        img_arr = np.array(f[ds_keys[1]])    \n",
    "        label_arr = np.array(f[ds_keys[2]])        \n",
    "        return [\n",
    "            {\n",
    "                DefaultDataKeys.INPUT: img,\n",
    "                DefaultDataKeys.TARGET: label\n",
    "            } \n",
    "            for img, label in list(zip(img_arr, label_arr))]\n",
    "\n",
    "    def load_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        sample[DefaultDataKeys.INPUT] = Image.fromarray(np.uint8(sample[DefaultDataKeys.INPUT])).convert('RGB')\n",
    "        return sample\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from typing import Optional\n",
    "from flash.core.data.process import Preprocess\n",
    "from flash.core.data.data_source import DefaultDataKeys, DefaultDataSources\n",
    "\n",
    "class SignsPreprocess(Preprocess):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_transform: Optional[Dict[str, Callable]] = None,\n",
    "        val_transform: Optional[Dict[str, Callable]] = None,\n",
    "        test_transform: Optional[Dict[str, Callable]] = None,\n",
    "        predict_transform: Optional[Dict[str, Callable]] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            train_transform=train_transform,\n",
    "            val_transform=val_transform,\n",
    "            test_transform=test_transform,\n",
    "            predict_transform=predict_transform,\n",
    "            data_sources={\n",
    "                DefaultDataSources.FILES: SignsDataSource(),\n",
    "            },\n",
    "            default_data_source=DefaultDataSources.FILES,\n",
    "        )\n",
    "\n",
    "    def default_transforms(self) -> Dict[str, Callable]:\n",
    "        return {\n",
    "            \"to_tensor_transform\": transforms.ToTensor(),\n",
    "            \"post_tensor_transform\": transforms.Normalize(\n",
    "                torch.tensor([0.485, 0.456, 0.406]), \n",
    "                torch.tensor([0.229, 0.224, 0.225])\n",
    "                ),\n",
    "            \"collate\": torch.utils.data._utils.collate.default_collate\n",
    "        }        \n",
    "\n",
    "    def get_state_dict(self) -> Dict[str, Any]:\n",
    "        return {**self.transforms}\n",
    "\n",
    "    @classmethod\n",
    "    def load_state_dict(cls, state_dict: Dict[str, Any], strict: bool = False):\n",
    "        return cls(**state_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# for a training and label data in form of numpy arrays, return a fold_index array whose elements\n",
    "# represent the fold index. The length of this fold_index array is same as length of input dataset\n",
    "# and the items for which fold_index array value == cv iteration count are to be used for validation \n",
    "# in the corresponding cross validation iteration with rest of the items ( for which fold_index \n",
    "# array value != cv iteration count ) being used for training (typical ration being 80:20)\n",
    "def get_skf_index(num_folds, X, y):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = 42)\n",
    "    train_fold_index = np.zeros(len(y))\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=X, y=y)):\n",
    "        train_fold_index[val_index] = [fold + 1] * len(val_index)\n",
    "    return train_fold_index\n",
    "\n",
    "k_folds = get_skf_index(num_folds=NUM_FOLDS, X=train_x, y=train_y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def split_data(fold, kfolds, X, y):\n",
    "    train_X = X[kfolds != fold+1]        \n",
    "    train_y = y[kfolds != fold+1]    \n",
    "    val_X = X[kfolds == fold+1]\n",
    "    val_y = y[kfolds == fold+1]\n",
    "    return train_X, train_y, val_X, val_y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from flash.image.classification.transforms import default_transforms\n",
    "from flash.core.data.transforms import ApplyToKeys\n",
    "from flash.core.data.data_source import DefaultDataKeys\n",
    "from flash.image import ImageClassificationData\n",
    "\n",
    "train_X, train_y, val_X, val_y = split_data(0, k_folds, train_x, train_y)\n",
    "\n",
    "signs_default_transform = {\n",
    "    \"to_tensor_transform\": nn.Sequential(\n",
    "            ApplyToKeys(DefaultDataKeys.INPUT, transforms.ToTensor()),\n",
    "            ApplyToKeys(DefaultDataKeys.TARGET, torch.as_tensor),\n",
    "        ),\n",
    "        \"post_tensor_transform\": ApplyToKeys(\n",
    "            DefaultDataKeys.INPUT,\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    \"collate\": torch.utils.data._utils.collate.default_collate\n",
    "}\n",
    "\n",
    "data_module = ImageClassificationData.from_numpy(\n",
    "    train_data = train_X,\n",
    "    train_targets= train_y,\n",
    "    val_data = val_X,\n",
    "    val_targets = val_y,\n",
    "    predict_data = test_x,    \n",
    "    train_transform = signs_default_transform,\n",
    "    val_transform = signs_default_transform,    \n",
    "    predict_transform = signs_default_transform,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = NUM_WORKERS\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "item = data_module.val_dataset[10]\n",
    "print(item[DefaultDataKeys.TARGET])\n",
    "type(item[DefaultDataKeys.INPUT])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from flash.image import ImageClassifier\n",
    "model = ImageClassifier(backbone=\"resnet18\", num_classes=6 )\n",
    "\n",
    "trainer = flash.Trainer(max_epochs=20, gpus=torch.cuda.device_count())\n",
    "trainer.finetune(model, datamodule=data_module, strategy=\"freeze_unfreeze\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.prepare_data has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.prepare_data.\n",
      "  rank_zero_deprecation(\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type           | Params\n",
      "-------------------------------------------------\n",
      "0 | train_metrics | ModuleDict     | 0     \n",
      "1 | val_metrics   | ModuleDict     | 0     \n",
      "2 | adapter       | DefaultAdapter | 11.2 M\n",
      "-------------------------------------------------\n",
      "12.7 K    Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.718    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9db2a35e76104d51b429481c095cb2ee"
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20df4243ae1e4bec9498129633138cba"
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac666788a91a46b49d2859931e790ecb"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd3c0cfde1c440b9823f43eb564f01da"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfd5d594e24d4396b0475af35152635f"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d766a0120554d748a924d335ad880f7"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd5f106603674fc496281d5ac55a57e4"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6576ef9829dd4390b287a4ee37c4eb00"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d6244b8235b440aaf85b3ccc58ccec1"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9690deea1ad745d5b827b78dce6ff3a1"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "048138c88c4445dabc8599e47c625b2a"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6750ff2e3e344bf993d5f465137bb7a"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/callbacks/finetuning.py:215: UserWarning: The provided params to be freezed already exist within another group of this optimizer. Those parameters will be skipped.\n",
      "HINT: Did you init your optimizer in `configure_optimizer` as such:\n",
      " <class 'torch.optim.adam.Adam'>(filter(lambda p: p.requires_grad, self.parameters()), ...) \n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "220d4c0c7e8b4d518fbdc703ad7984c5"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed357ad9fc8d4be3830bcb8ecfabb6af"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "047235db7d4a4c1f8e54481728990476"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acd2f30bc5a84d008a57799bad63d2de"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c991bdfbd44e47eabd302e9c3afe6375"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2411bb9675bf49b9bf38da0d4acc5ec3"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6b95b6a6ec648b39ede2f8cd60e1b6a"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72b4768ae135421589e452128055e049"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01be9050b5f7450eb0403c7aa1b87372"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3c2d07088b04d148d7007442cda9509"
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "predictions = model.predict(test_x, data_source=DefaultDataSources.NUMPY)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/flash/core/classification.py:217: UserWarning: No LabelsState was found, this serializer will act as a Classes serializer.\n",
      "  rank_zero_warn(\"No LabelsState was found, this serializer will act as a Classes serializer.\", UserWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def test_accuracy(test_labels, test_predictions):\n",
    "    incorrect_preds = []\n",
    "    for index, test_label in enumerate(test_labels):\n",
    "        if test_label != test_predictions[index] :\n",
    "            incorrect_preds.append((test_label, test_predictions[index]))\n",
    "\n",
    "    test_accuracy = (len(test_labels) - len(incorrect_preds)) / len(test_labels)\n",
    "    return round(test_accuracy, 4), incorrect_preds\n",
    "\n",
    "test_acc, test_incorrect_preds = test_accuracy(test_y.tolist(), predictions)\n",
    "print(f\"Accuracy of Resnet18 on test set is {test_acc * 100} %\")    \n",
    "print(f\"Incorrect predictions = {len(test_incorrect_preds)} \")\n",
    "for item in test_incorrect_preds:\n",
    "    print(f\"Actual label = {item[0]}, Predicted label = {item[1]}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of Resnet18 on test set is 97.5 %\n",
      "Incorrect predictions = 3 \n",
      "Actual label = 2, Predicted label = 1\n",
      "Actual label = 2, Predicted label = 1\n",
      "Actual label = 5, Predicted label = 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "%tensorboard --logdir lightning_logs/version_6"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)"
  },
  "interpreter": {
   "hash": "148f3469c78c75f496aee59433c1c8be3c885ccea1b507530cbeda0a24e0e40d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}