{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "def get_imgs_labels(h5_file_path):\n",
    "    f = h5py.File(h5_file_path, \"r\")\n",
    "    ds_keys = [key for key in f.keys()]\n",
    "    imgs = np.array(f[ds_keys[1]])    \n",
    "    labels = np.array(f[ds_keys[2]])\n",
    "    list_classes = np.array(f[ds_keys[0]])\n",
    "    imgs = np.transpose(imgs, (0, 3, 1, 2))\n",
    "    return imgs, labels, list_classes\n",
    "\n",
    "train_x, train_y, train_classes = get_imgs_labels(\"./datasets/train_signs.h5\")\n",
    "test_x, test_y, test_classes = get_imgs_labels(\"./datasets/test_signs.h5\")\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "#timm.list_models(filter=\"efficient*\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "class Config:\n",
    "    NUM_FOLDS = 5\n",
    "    NUM_CLASSES = 6\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 4\n",
    "    NUM_EPOCHS = 5\n",
    "    TRAIN_IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    TRAIN_IMG_STD = [0.229, 0.224, 0.225]\n",
    "    UNFREEZE_EPOCH_NO = 2\n",
    "    PRECISION = 16\n",
    "\n",
    "class TransformationType:\n",
    "    TORCHVISION = \"torchvision\"\n",
    "    ALB = \"albumentations\"\n",
    "\n",
    "class Models:\n",
    "    RESNET34 = \"resnet34\"\n",
    "    RESNET50 = \"resnet50\"\n",
    "    RESNEXT50 = \"resnext50_32x4d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a training and label data in form of numpy arrays, return a fold_index array whose elements\n",
    "# represent the fold index. The length of this fold_index array is same as length of input dataset\n",
    "# and the items for which fold_index array value == cv iteration count are to be used for validation \n",
    "# in the corresponding cross validation iteration with rest of the items ( for which fold_index \n",
    "# array value != cv iteration count ) being used for training (typical ration being 80:20)\n",
    "def get_skf_index(num_folds, X, y):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = 42)\n",
    "    train_fold_index = np.zeros(len(y))\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=X, y=y)):\n",
    "        train_fold_index[val_index] = [fold + 1] * len(val_index)\n",
    "    return train_fold_index\n",
    "\n",
    "k_folds = get_skf_index(num_folds=Config.NUM_FOLDS, X=train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpArrayImageDataset(Dataset):\n",
    "    def __init__(self, img_arr, label_arr, transform, target_transform, \n",
    "                transform_type=TransformationType.TORCHVISION):\n",
    "        self.img_arr = img_arr\n",
    "        self.label_arr = label_arr\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.transform_type = transform_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_arr)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tfmd_img = self.img_arr[index]\n",
    "        tfmd_img = tfmd_img.transpose(1,2,0)\n",
    "        #print(type(tfmd_img), tfmd_img.shape)\n",
    "        tfmd_label = self.label_arr[index]\n",
    "        if self.transform:\n",
    "            if self.transform_type == TransformationType.TORCHVISION:                        \n",
    "                tfmd_img = self.transform(tfmd_img)\n",
    "            elif self.transform_type == TransformationType.ALB:\n",
    "                augmented = self.transform(image=tfmd_img)\n",
    "                tfmd_img = augmented[\"image\"]                   \n",
    "        if self.target_transform:               \n",
    "            tfmd_label = self.target_transform(tfmd_label)              \n",
    "        return tfmd_img, tfmd_label            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Normalize(Config.TRAIN_IMG_MEAN, Config.TRAIN_IMG_STD)])\n",
    "\n",
    "# Get the train and validation data loaders for a specific fold. \n",
    "# X: numpy array of input features\n",
    "# y: numpy array of target labels\n",
    "# fold: fold index for which to create data loaders                                     \n",
    "# kfolds: Array that marks each of the data items as belonging to a specific fold\n",
    "def get_fold_dls(fold, kfolds, X, y):\n",
    "    fold += 1                         \n",
    "    train_X = X[kfolds != fold]        \n",
    "    train_y = y[kfolds != fold]    \n",
    "    val_X = X[kfolds == fold]\n",
    "    val_y = y[kfolds == fold]\n",
    "    ds_train = NpArrayImageDataset(train_X, train_y, transform=img_transforms, target_transform=torch.as_tensor)\n",
    "    ds_val = NpArrayImageDataset(val_X, val_y, transform=img_transforms, target_transform=torch.as_tensor)\n",
    "    dl_train = DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)\n",
    "    dl_val = DataLoader(ds_val, batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS)\n",
    "    return dl_train, dl_val, ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images along with their labels from a batch where images are in form of numpy arrays \n",
    "# if predictions are provided along with labels, these are displayed too\n",
    "def show_batch(img_ds, num_items, num_rows, num_cols, predict_arr=None):\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    img_index = np.random.randint(0, len(img_ds)-1, num_items)\n",
    "    for index, img_index in enumerate(img_index):  # list first 9 images\n",
    "        img, lb = img_ds[img_index]            \n",
    "        ax = fig.add_subplot(num_rows, num_cols, index + 1, xticks=[], yticks=[])\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().numpy()\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # the image data has RGB channels at dim 0, the shape of 3, 64, 64 needs to be 64, 64, 3 for display            \n",
    "            img = img.transpose(1, 2, 0)\n",
    "            ax.imshow(Image.fromarray(np.uint8(img)).convert('RGB'))        \n",
    "        if isinstance(lb, torch.Tensor):\n",
    "            # extract the label from label tensor\n",
    "            lb = lb.item()            \n",
    "        title = f\"Actual: {lb}\"\n",
    "        if predict_arr: \n",
    "            title += f\", Pred: {predict_arr[img_index]}\"        \n",
    "        ax.set_title(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_val, ds_train, ds_val = get_fold_dls(0, k_folds, train_x, train_y)\n",
    "#len(ds_val)\n",
    "show_batch(ds_val, 3, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class ImageClassificationModel(nn.Module):\n",
    "    @staticmethod\n",
    "    def get_backbone_classifier(model_to_use, drop_out, num_classes):\n",
    "        pt_model = timm.create_model(model_to_use, pretrained=True)\n",
    "        backbone = None\n",
    "        classifier = None\n",
    "        if model_to_use in [Models.RESNET34, Models.RESNET50, Models.RESNEXT50]:            \n",
    "            backbone = nn.Sequential(*list(pt_model.children())[:-1])\n",
    "            in_features = pt_model.fc.in_features\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Dropout(drop_out),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )    \n",
    "        return backbone, classifier\n",
    "\n",
    "    def __init__(self, num_classes, drop_out=0.25, model_to_use=\"resnext\"):\n",
    "        super().__init__()                \n",
    "        self.num_classes = num_classes        \n",
    "        self.backbone, self.classifier = self.get_backbone_classifier(model_to_use, drop_out, num_classes)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = torch.flatten(features, 1)                \n",
    "        x = self.classifier(features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class ImageClassificationLitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, hparams, model_to_use):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        #self.hparams = hparams\n",
    "        #self.model = ImageClassificationModel(num_classes, hparams[\"drop_out\"], model_to_use)\n",
    "        self.lr = hparams[\"lr\"]\n",
    "        self.num_classes = num_classes        \n",
    "        self.backbone, self.classifier = self.get_backbone_classifier(model_to_use, hparams[\"drop_out\"], num_classes) \n",
    "        #self.loss_fn = F.cross_entropy\n",
    "        #self.train_metric = torchmetrics.Accuracy()\n",
    "        #self.val_metric = torchmetrics.Accuracy()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_backbone_classifier(model_to_use, drop_out, num_classes):\n",
    "        pt_model = timm.create_model(model_to_use, pretrained=True)\n",
    "        backbone = None\n",
    "        classifier = None\n",
    "        if model_to_use in [Models.RESNET34, Models.RESNET50, Models.RESNEXT50]:            \n",
    "            backbone = nn.Sequential(*list(pt_model.children())[:-1])\n",
    "            in_features = pt_model.fc.in_features\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Dropout(drop_out),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )    \n",
    "        return backbone, classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = torch.flatten(features, 1)                \n",
    "        x = self.classifier(features)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        model_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, \"min\")        \n",
    "        return {\n",
    "            \"optimizer\": model_optimizer, \n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        loss = cross_entropy(y_pred, y)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", acc, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return loss        \n",
    "\n",
    "    # def training_epoch_end(self, outputs):\n",
    "    #     train_epoch_acc = self.train_metric.compute()\n",
    "    #     self.log(\"train_accuracy\", train_epoch_acc, on_step=False, on_epoch=False, logger=True, prog_bar=True)        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        val_loss = cross_entropy(y_pred, y)\n",
    "        val_acc = accuracy(y_pred, y)\n",
    "        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", val_acc, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return val_loss                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning\n",
    "\n",
    "# For results reproducibility \n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "pl.seed_everything(42, workers=True)\n",
    "multiplicative = lambda epoch: 1.5\n",
    "backbone_finetuning = BackboneFinetuning(Config.UNFREEZE_EPOCH_NO, multiplicative, verbose=True)\n",
    "\n",
    "# model hyperparameters\n",
    "model_params = {    \n",
    "    \"drop_out\": 0.25,\n",
    "    \"lr\": 0.000366\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hparam_tuning(dl_train, dl_val, model_params):\n",
    "    signs_model = ImageClassificationLitModel(\n",
    "        num_classes=Config.NUM_CLASSES, \n",
    "        hparams=model_params,        \n",
    "        model_to_use=Models.RESNET50\n",
    "        )  \n",
    "    trainer = pl.Trainer(\n",
    "        checkpoint_callback=False,        \n",
    "        gpus=1,\n",
    "        # For results reproducibility \n",
    "        deterministic=True,\n",
    "        auto_select_gpus=True,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        max_epochs=Config.NUM_EPOCHS,        \n",
    "        precision=Config.PRECISION,                        \n",
    "        callbacks=[backbone_finetuning]\n",
    "    )      \n",
    "    trainer.fit(signs_model, train_dataloaders=dl_train, val_dataloaders=dl_val)     \n",
    "    return trainer.callback_metrics[\"val_loss\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(dl_train, dl_val, model_params, fold=None):    \n",
    "    fold_str = f\"fold_{fold}\"\n",
    "    tb_logger = None\n",
    "    chkpt_file_name = \"best_model_{epoch}_{val_loss:.4f}\"\n",
    "    if fold:       \n",
    "        chkpt_file_name = fold_str + \"_\" + chkpt_file_name\n",
    "        tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", version=fold_str)\n",
    "    else:\n",
    "        tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\")        \n",
    "    signs_model = ImageClassificationLitModel(\n",
    "        num_classes=Config.NUM_CLASSES, \n",
    "        hparams=model_params,        \n",
    "        model_to_use=Models.RESNET50\n",
    "        )    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"./model\", \n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\", \n",
    "        filename=chkpt_file_name\n",
    "        )\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        # For results reproducibility \n",
    "        deterministic=True,\n",
    "        auto_select_gpus=True,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        max_epochs=Config.NUM_EPOCHS,\n",
    "        logger=tb_logger,\n",
    "        auto_lr_find=True,    \n",
    "        precision=Config.PRECISION,                        \n",
    "        callbacks=[checkpoint_callback, backbone_finetuning]\n",
    "    )\n",
    "    trainer.tune(model=signs_model, train_dataloaders=dl_train)\n",
    "    print(signs_model.lr)\n",
    "    trainer.fit(signs_model, train_dataloaders=dl_train, val_dataloaders=dl_val)                \n",
    "    del trainer, signs_model        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-6, 1e-3),\n",
    "        \"drop_out\": trial.suggest_uniform(\"drop_out\", 0.2, 0.7)\n",
    "    }\n",
    "    dl_train, dl_val, ds_train, ds_val = get_fold_dls(0, k_folds, train_x, train_y)    \n",
    "    loss = run_hparam_tuning(dl_train, dl_val, params)\n",
    "    return loss\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"SignsImageClassificationTuning\")    \n",
    "study.optimize(objective, n_trials=10)\n",
    "print(f\"Best trial number = {study.best_trial.number}\")\n",
    "print(\"Best trial params:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in range(Config.NUM_FOLDS):\n",
    "#     dl_train, dl_val, ds_train, ds_val = get_fold_dls(fold, k_folds, train_x, train_y)\n",
    "#     run_training(dl_train, dl_val, model_params, fold)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "148f3469c78c75f496aee59433c1c8be3c885ccea1b507530cbeda0a24e0e40d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
