{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 3, 64, 64) (1080,)\n",
      "(120, 3, 64, 64) (120,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "def get_imgs_labels(h5_file_path):\n",
    "    f = h5py.File(h5_file_path, \"r\")\n",
    "    ds_keys = [key for key in f.keys()]\n",
    "    imgs = np.array(f[ds_keys[1]])    \n",
    "    labels = np.array(f[ds_keys[2]])\n",
    "    list_classes = np.array(f[ds_keys[0]])\n",
    "    imgs = np.transpose(imgs, (0, 3, 1, 2))\n",
    "    return imgs, labels, list_classes\n",
    "\n",
    "train_x, train_y, train_classes = get_imgs_labels(\"./datasets/train_signs.h5\")\n",
    "test_x, test_y, test_classes = get_imgs_labels(\"./datasets/test_signs.h5\")\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "#timm.list_models(filter=\"efficient*\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "class Config:\n",
    "    NUM_FOLDS = 5\n",
    "    NUM_CLASSES = 6\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 4\n",
    "    NUM_EPOCHS = 10\n",
    "    TRAIN_IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    TRAIN_IMG_STD = [0.229, 0.224, 0.225]\n",
    "    UNFREEZE_EPOCH_NO = 2\n",
    "    PRECISION = 16\n",
    "\n",
    "class TransformationType:\n",
    "    TORCHVISION = \"torchvision\"\n",
    "    ALB = \"albumentations\"\n",
    "\n",
    "class Models:\n",
    "    RESNET34 = \"resnet34\"\n",
    "    RESNET50 = \"resnet50\"\n",
    "    RESNEXT50 = \"resnext50_32x4d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a training and label data in form of numpy arrays, return a fold_index array whose elements\n",
    "# represent the fold index. The length of this fold_index array is same as length of input dataset\n",
    "# and the items for which fold_index array value == cv iteration count are to be used for validation \n",
    "# in the corresponding cross validation iteration with rest of the items ( for which fold_index \n",
    "# array value != cv iteration count ) being used for training (typical ration being 80:20)\n",
    "def get_skf_index(num_folds, X, y):\n",
    "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state = 42)\n",
    "    train_fold_index = np.zeros(len(y))\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=X, y=y)):\n",
    "        train_fold_index[val_index] = [fold + 1] * len(val_index)\n",
    "    return train_fold_index\n",
    "\n",
    "k_folds = get_skf_index(num_folds=Config.NUM_FOLDS, X=train_x, y=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpArrayImageDataset(Dataset):\n",
    "    def __init__(self, img_arr, label_arr, transform, target_transform, \n",
    "                transform_type=TransformationType.TORCHVISION):\n",
    "        self.img_arr = img_arr\n",
    "        self.label_arr = label_arr\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.transform_type = transform_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_arr)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tfmd_img = self.img_arr[index]\n",
    "        tfmd_img = tfmd_img.transpose(1,2,0)\n",
    "        #print(type(tfmd_img), tfmd_img.shape)\n",
    "        tfmd_label = self.label_arr[index]\n",
    "        if self.transform:\n",
    "            if self.transform_type == TransformationType.TORCHVISION:                        \n",
    "                tfmd_img = self.transform(tfmd_img)\n",
    "            elif self.transform_type == TransformationType.ALB:\n",
    "                augmented = self.transform(image=tfmd_img)\n",
    "                tfmd_img = augmented[\"image\"]                   \n",
    "        if self.target_transform:               \n",
    "            tfmd_label = self.target_transform(tfmd_label)              \n",
    "        return tfmd_img, tfmd_label            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = transforms.Compose([transforms.ToTensor(), \n",
    "                                     transforms.Normalize(Config.TRAIN_IMG_MEAN, Config.TRAIN_IMG_STD)])\n",
    "\n",
    "# Get the train and validation data loaders for a specific fold. \n",
    "# X: numpy array of input features\n",
    "# y: numpy array of target labels\n",
    "# fold: fold index for which to create data loaders                                     \n",
    "# kfolds: Array that marks each of the data items as belonging to a specific fold\n",
    "def get_fold_dls(fold, kfolds, X, y):\n",
    "    fold += 1                         \n",
    "    train_X = X[kfolds != fold]        \n",
    "    train_y = y[kfolds != fold]    \n",
    "    val_X = X[kfolds == fold]\n",
    "    val_y = y[kfolds == fold]\n",
    "    ds_train = NpArrayImageDataset(train_X, train_y, transform=img_transforms, target_transform=torch.as_tensor)\n",
    "    ds_val = NpArrayImageDataset(val_X, val_y, transform=img_transforms, target_transform=torch.as_tensor)\n",
    "    dl_train = DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)\n",
    "    dl_val = DataLoader(ds_val, batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS)\n",
    "    return dl_train, dl_val, ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images along with their labels from a batch where images are in form of numpy arrays \n",
    "# if predictions are provided along with labels, these are displayed too\n",
    "def show_batch(img_ds, num_items, num_rows, num_cols, predict_arr=None):\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    img_index = np.random.randint(0, len(img_ds)-1, num_items)\n",
    "    for index, img_index in enumerate(img_index):  # list first 9 images\n",
    "        img, lb = img_ds[img_index]            \n",
    "        ax = fig.add_subplot(num_rows, num_cols, index + 1, xticks=[], yticks=[])\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().numpy()\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # the image data has RGB channels at dim 0, the shape of 3, 64, 64 needs to be 64, 64, 3 for display            \n",
    "            img = img.transpose(1, 2, 0)\n",
    "            ax.imshow(Image.fromarray(np.uint8(img)).convert('RGB'))        \n",
    "        if isinstance(lb, torch.Tensor):\n",
    "            # extract the label from label tensor\n",
    "            lb = lb.item()            \n",
    "        title = f\"Actual: {lb}\"\n",
    "        if predict_arr: \n",
    "            title += f\", Pred: {predict_arr[img_index]}\"        \n",
    "        ax.set_title(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl_train, dl_val, ds_train, ds_val = get_fold_dls(0, k_folds, train_x, train_y)\n",
    "#len(ds_val)\n",
    "show_batch(ds_val, 3, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class ImageClassificationModel(nn.Module):\n",
    "    @staticmethod\n",
    "    def get_backbone_classifier(model_to_use, drop_out, num_classes):\n",
    "        pt_model = timm.create_model(model_to_use, pretrained=True)\n",
    "        backbone = None\n",
    "        classifier = None\n",
    "        if model_to_use in [Models.RESNET34, Models.RESNET50, Models.RESNEXT50]:            \n",
    "            backbone = nn.Sequential(*list(pt_model.children())[:-1])\n",
    "            in_features = pt_model.fc.in_features\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Dropout(drop_out),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )    \n",
    "        return backbone, classifier\n",
    "\n",
    "    def __init__(self, num_classes, drop_out=0.25, model_to_use=\"resnext\"):\n",
    "        super().__init__()                \n",
    "        self.num_classes = num_classes        \n",
    "        self.backbone, self.classifier = self.get_backbone_classifier(model_to_use, drop_out, num_classes)    \n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = torch.flatten(features, 1)                \n",
    "        x = self.classifier(features)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class ImageClassificationLitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, hparams, model_to_use):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = hparams[\"lr\"]\n",
    "        self.num_classes = num_classes        \n",
    "        self.backbone, self.classifier = self.get_backbone_classifier(model_to_use, hparams[\"drop_out\"], num_classes) \n",
    "\n",
    "    @staticmethod\n",
    "    def get_backbone_classifier(model_to_use, drop_out, num_classes):\n",
    "        pt_model = timm.create_model(model_to_use, pretrained=True)\n",
    "        backbone = None\n",
    "        classifier = None\n",
    "        if model_to_use in [Models.RESNET34, Models.RESNET50, Models.RESNEXT50]:            \n",
    "            backbone = nn.Sequential(*list(pt_model.children())[:-1])\n",
    "            in_features = pt_model.fc.in_features\n",
    "            classifier = nn.Sequential(\n",
    "                nn.Dropout(drop_out),\n",
    "                nn.Linear(in_features, num_classes)\n",
    "            )    \n",
    "        return backbone, classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features = torch.flatten(features, 1)                \n",
    "        x = self.classifier(features)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        model_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, \"min\")        \n",
    "        return {\n",
    "            \"optimizer\": model_optimizer, \n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        loss = cross_entropy(y_pred, y)\n",
    "        acc = accuracy(y_pred, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", acc, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return loss        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self(X)\n",
    "        val_loss = cross_entropy(y_pred, y)\n",
    "        val_acc = accuracy(y_pred, y)\n",
    "        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", val_acc, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return val_loss                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning, EarlyStopping\n",
    "\n",
    "# For results reproducibility \n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# model hyperparameters\n",
    "model_params = {    \n",
    "    \"drop_out\": 0.25,\n",
    "    \"lr\": 0.000366\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "def run_hparam_tuning(model_params, trial):\n",
    "    dl_train, dl_val, ds_train, ds_val = get_fold_dls(0, k_folds, train_x, train_y)    \n",
    "    early_stopping = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
    "    backbone_finetuning_cb = BackboneFinetuning(Config.UNFREEZE_EPOCH_NO, multiplicative, verbose=False)\n",
    "    signs_model = ImageClassificationLitModel(\n",
    "        num_classes=Config.NUM_CLASSES, \n",
    "        hparams=model_params,        \n",
    "        model_to_use=Models.RESNET50\n",
    "        )  \n",
    "    trainer = pl.Trainer(\n",
    "        checkpoint_callback=False,        \n",
    "        gpus=1,\n",
    "        # For results reproducibility \n",
    "        deterministic=True,\n",
    "        auto_select_gpus=True,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        max_epochs=Config.NUM_EPOCHS,        \n",
    "        precision=Config.PRECISION,   \n",
    "        weights_summary=None,                     \n",
    "        callbacks=[backbone_finetuning_cb, early_stopping]\n",
    "    )      \n",
    "    trainer.fit(signs_model, train_dataloaders=dl_train, val_dataloaders=dl_val)     \n",
    "    loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "    del trainer, signs_model, early_stopping, backbone_finetuning_cb, dl_train, dl_val\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"lr\": trial.suggest_loguniform(\"lr\", 1e-6, 1e-3),\n",
    "#         \"drop_out\": trial.suggest_uniform(\"drop_out\", 0.2, 0.7)\n",
    "#     }    \n",
    "#     loss = run_hparam_tuning(params, trial)\n",
    "#     return loss\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", study_name=\"SignsImageClassificationTuning\")    \n",
    "# study.optimize(objective, n_trials=10)\n",
    "# print(f\"Best trial number = {study.best_trial.number}\")\n",
    "# print(\"Best trial params:\")\n",
    "# print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:101: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  rank_zero_warn(f\"you defined a {step_name} but have no {loader_name}. Skipping {stage} loop\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "Global seed set to 42\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (14) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a498963e710d4722b05a4554715c6ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0010964781961431851\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010964781961431851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "65.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ba541031bb46fdaa28d261067d0f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4df8827e3843c8b9246030501e061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98bef0e2bbd42a298f656bba3800ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.293\n",
      "Epoch 0, global step 13: val_loss reached 1.29323 (best 1.29323), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold0_best_model_epoch=0_val_loss=1.2932.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c86f45a32b24db0819e97a5a4737506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.344 >= min_delta = 0.0. New best score: 0.950\n",
      "Epoch 1, global step 27: val_loss reached 0.94973 (best 0.94973), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold0_best_model_epoch=1_val_loss=0.9497.ckpt\" as top 1\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/callbacks/finetuning.py:215: UserWarning: The provided params to be freezed already exist within another group of this optimizer. Those parameters will be skipped.\n",
      "HINT: Did you init your optimizer in `configure_optimizer` as such:\n",
      " <class 'torch.optim.adam.Adam'>(filter(lambda p: p.requires_grad, self.parameters()), ...) \n",
      "  rank_zero_warn(\n",
      "Current lr: 0.001096478196, Backbone lr: 0.00010964782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732d122a77b48568ef9bb37c23541b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.772 >= min_delta = 0.0. New best score: 0.177\n",
      "Epoch 2, global step 41: val_loss reached 0.17749 (best 0.17749), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold0_best_model_epoch=2_val_loss=0.1775.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000164471729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd8f9d6819f417bb9f70b91c58bc762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.079 >= min_delta = 0.0. New best score: 0.098\n",
      "Epoch 3, global step 55: val_loss reached 0.09819 (best 0.09819), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold0_best_model_epoch=3_val_loss=0.0982.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000246707594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d882046e6fe4f9b8f4be38ea7e8febb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 69: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000370061391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0623a632f1f1433fba1fe81784596700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 83: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000555092087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa2384d3d94260875bac697f44110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 97: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.00083263813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933c6c6263db450a9ecfeaa621808e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 111: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.001096478196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23f3dbf4d2e4374b5d2e3267a3e2e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.085\n",
      "Epoch 8, global step 125: val_loss reached 0.08531 (best 0.08531), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold0_best_model_epoch=8_val_loss=0.0853.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.001096478196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaaf966181c4ee09c15ae0922f35b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 139: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory ./model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f5c805a1b4549af8b32a4b8b746d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0010964781961431851\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010964781961431851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "65.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b9ea0ed988466e8f14c22ee7b662d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3475531409bf47f28fe10f8c484d97c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a774d84df8574e9291cf4d4dee1cb3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.294\n",
      "Epoch 0, global step 13: val_loss reached 1.29439 (best 1.29439), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold1_best_model_epoch=0_val_loss=1.2944.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2a512fe9b9459b95b14b89c734be09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.395 >= min_delta = 0.0. New best score: 0.900\n",
      "Epoch 1, global step 27: val_loss reached 0.89976 (best 0.89976), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold1_best_model_epoch=1_val_loss=0.8998.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.00010964782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad5ed3d61fe47ba9c43993429fa864b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.743 >= min_delta = 0.0. New best score: 0.156\n",
      "Epoch 2, global step 41: val_loss reached 0.15639 (best 0.15639), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold1_best_model_epoch=2_val_loss=0.1564.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000164471729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed123358dd864ca0963c5ccdd814086b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.090 >= min_delta = 0.0. New best score: 0.066\n",
      "Epoch 3, global step 55: val_loss reached 0.06604 (best 0.06604), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold1_best_model_epoch=3_val_loss=0.0660.ckpt\" as top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000246707594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5518946589124e63aa51c15074991ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 69: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000370061391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5825118200940e1ba17151f64e9fed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 83: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.000555092087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0041f2149ff74886a806a809ba1bb2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 97: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.00083263813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506df9223333475493dd082c02f58293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 111: val_loss was not in top 1\n",
      "Current lr: 0.001096478196, Backbone lr: 0.001096478196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd95a24889c74e0199950f14632f0798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.066. Signaling Trainer to stop.\n",
      "Epoch 8, global step 125: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73807904a9c2446899b9c04178000506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0007585775750291836\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007585775750291836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "65.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa25eb0cf2748808529eaf44a00df80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bc1dd1a6d6475cb8b3e57b35cce782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66abe5164fc4b54b5ab656c70fdb6a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.414\n",
      "Epoch 0, global step 13: val_loss reached 1.41392 (best 1.41392), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold2_best_model_epoch=0_val_loss=1.4139.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21133fa486324304818a0997a3dbf82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.222 >= min_delta = 0.0. New best score: 1.192\n",
      "Epoch 1, global step 27: val_loss reached 1.19215 (best 1.19215), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold2_best_model_epoch=1_val_loss=1.1922.ckpt\" as top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 7.5857758e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91db7e6eb46e4a70811578cae69fe957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.764 >= min_delta = 0.0. New best score: 0.428\n",
      "Epoch 2, global step 41: val_loss reached 0.42814 (best 0.42814), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold2_best_model_epoch=2_val_loss=0.4281.ckpt\" as top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000113786636\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7fc967fe0e46c1a9f03f9bba475b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.322 >= min_delta = 0.0. New best score: 0.106\n",
      "Epoch 3, global step 55: val_loss reached 0.10625 (best 0.10625), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold2_best_model_epoch=3_val_loss=0.1063.ckpt\" as top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000170679954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a2b8b674bf4e3a8464113edf59afc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 69: val_loss was not in top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000256019932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447f153b22a24a64b6474d8b4e79ec52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 83: val_loss was not in top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000384029897\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f56f35f89f4feeb4e6857bed34f25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 97: val_loss was not in top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000576044846\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c873fd1352204134b115d28c3aef3b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 111: val_loss was not in top 1\n",
      "Current lr: 0.000758577575, Backbone lr: 0.000758577575\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20f92ab8fe044e79030be58570b8b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.106. Signaling Trainer to stop.\n",
      "Epoch 8, global step 125: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5278813be1c437abcd64e7d1252c14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0009120108393559097\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009120108393559097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "65.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297f7603674b4cf9b0570f605f067d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e367f16f91e45fda26df141a1326323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1b5fcafaed49558b6673ad5a1b4d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.359\n",
      "Epoch 0, global step 13: val_loss reached 1.35909 (best 1.35909), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold3_best_model_epoch=0_val_loss=1.3591.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d77dcb4f32444991187582152fe1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.314 >= min_delta = 0.0. New best score: 1.045\n",
      "Epoch 1, global step 27: val_loss reached 1.04490 (best 1.04490), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold3_best_model_epoch=1_val_loss=1.0449.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 9.1201084e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b19ca5ae42a4e7f9e74de9c74cd9915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.781 >= min_delta = 0.0. New best score: 0.264\n",
      "Epoch 2, global step 41: val_loss reached 0.26352 (best 0.26352), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold3_best_model_epoch=2_val_loss=0.2635.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000136801626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fb6f6ff37c40c88a40b7420e6d12c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.198 >= min_delta = 0.0. New best score: 0.066\n",
      "Epoch 3, global step 55: val_loss reached 0.06578 (best 0.06578), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold3_best_model_epoch=3_val_loss=0.0658.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000205202439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d96eb9292a4e21b08242a477c25db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 69: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000307803658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0e4bf0315344cc9900c5e70e501f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 83: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000461705487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e734bd3be2ce42c69de276b9d8cab796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 97: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000692558231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba841451f8e4d8a8363cc638403a6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 111: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000912010839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d504ba9621044408f1815506daee0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.066. Signaling Trainer to stop.\n",
      "Epoch 8, global step 125: val_loss was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4657301b292c49ebbd0517fd48edc4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.0009120108393559097\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009120108393559097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | backbone   | Sequential | 23.5 M\n",
      "1 | classifier | Sequential | 12.3 K\n",
      "------------------------------------------\n",
      "65.4 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787f5fec9f2e4483bf59cf69776718f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7f20a6599648379c7648483c6154d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98590cb2e1ba416aa2d99f6ae170518e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.310\n",
      "Epoch 0, global step 13: val_loss reached 1.30966 (best 1.30966), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold4_best_model_epoch=0_val_loss=1.3097.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c85b38fa314876b04736413575ae0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.287 >= min_delta = 0.0. New best score: 1.022\n",
      "Epoch 1, global step 27: val_loss reached 1.02233 (best 1.02233), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold4_best_model_epoch=1_val_loss=1.0223.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 9.1201084e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db1726fec0c447886e28f856d65dfdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.645 >= min_delta = 0.0. New best score: 0.377\n",
      "Epoch 2, global step 41: val_loss reached 0.37717 (best 0.37717), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold4_best_model_epoch=2_val_loss=0.3772.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000136801626\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34786ef6a9fe42179796d951839fb68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.304 >= min_delta = 0.0. New best score: 0.073\n",
      "Epoch 3, global step 55: val_loss reached 0.07305 (best 0.07305), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold4_best_model_epoch=3_val_loss=0.0730.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000205202439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd10b7247f349eca99e5ba394f9a78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.070\n",
      "Epoch 4, global step 69: val_loss reached 0.06996 (best 0.06996), saving model to \"/home/bk_anupam/code/ML/DeepLearningWSL/ComputerVision/CNN/model/fold4_best_model_epoch=4_val_loss=0.0700.ckpt\" as top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000307803658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e8b7175e11423c94c5a700458ce85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 83: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000461705487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5021ccd0554424bb3f45f04b485e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 97: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000692558231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066bb92dd7b34b3ab4c1b1037f73eee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 111: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000912010839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5043726d41524a98b6a9360825cd7270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 125: val_loss was not in top 1\n",
      "Current lr: 0.000912010839, Backbone lr: 0.000912010839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41bbc9238b14de8907612ce22601d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 5 records. Best score: 0.070. Signaling Trainer to stop.\n",
      "Epoch 9, global step 139: val_loss was not in top 1\n"
     ]
    }
   ],
   "source": [
    "find_lr = True\n",
    "\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    dl_train, dl_val, ds_train, ds_val = get_fold_dls(fold, k_folds, train_x, train_y)\n",
    "    fold_str = f\"fold{fold}\"\n",
    "    print(f\"Running training for {fold_str}\")\n",
    "    tb_logger = None\n",
    "    chkpt_file_name = \"best_model_{epoch}_{val_loss:.4f}\"\n",
    "    multiplicative = lambda epoch: 1.5\n",
    "    backbone_finetuning = BackboneFinetuning(Config.UNFREEZE_EPOCH_NO, multiplicative, verbose=True)\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", verbose=True)\n",
    "    if fold is not None:       \n",
    "        chkpt_file_name = fold_str + \"_\" + chkpt_file_name\n",
    "        tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", version=fold_str)\n",
    "    else:\n",
    "        tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\")        \n",
    "    signs_model = ImageClassificationLitModel(\n",
    "        num_classes=Config.NUM_CLASSES, \n",
    "        hparams=model_params,        \n",
    "        model_to_use=Models.RESNET50\n",
    "        )    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"./model\", \n",
    "        verbose=True,\n",
    "        monitor=\"val_loss\", \n",
    "        filename=chkpt_file_name\n",
    "        )\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        # For results reproducibility \n",
    "        deterministic=True,\n",
    "        auto_select_gpus=True,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        max_epochs=Config.NUM_EPOCHS,\n",
    "        logger=tb_logger,\n",
    "        auto_lr_find=True,    \n",
    "        precision=Config.PRECISION,                        \n",
    "        callbacks=[checkpoint_callback, backbone_finetuning, early_stopping_callback]\n",
    "    )\n",
    "    if find_lr:\n",
    "        trainer.tune(model=signs_model, train_dataloaders=dl_train)\n",
    "        print(signs_model.lr)\n",
    "    trainer.fit(signs_model, train_dataloaders=dl_train, val_dataloaders=dl_val)                \n",
    "    del trainer, signs_model, backbone_finetuning, early_stopping_callback  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "148f3469c78c75f496aee59433c1c8be3c885ccea1b507530cbeda0a24e0e40d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
